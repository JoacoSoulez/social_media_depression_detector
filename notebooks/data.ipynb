{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bedeefd-c5d0-4b5a-8546-444ca02c7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7bf71f-1e03-4823-9810-e097d1436eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../../raw_data/'\n",
    "\n",
    "def get_tweets(raw_data_path=raw_data_path):\n",
    "    \"\"\"\"Import a dataset of Tweets labeled as not depressive (0) and depressive (1)\"\"\"\n",
    "    # Import data from raw_data folder\n",
    "    data = pd.read_csv(f\"{raw_data_path}tweets/training.processed.noemoticon.csv\",\n",
    "                      encoding_errors='ignore',\n",
    "                      usecols=[0,5],\n",
    "                      header=None,\n",
    "                      names=['label','tweets'])\n",
    "    \n",
    "    # Remove missing values\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Filter only possitive Tweets\n",
    "    positive_tweets = data[data['label']==4].drop(columns='label').reset_index(drop=True)\n",
    "    \n",
    "    # Assign 0 to not depressive tweets\n",
    "    positive_tweets['label'] = 0\n",
    "    \n",
    "    # Import depressive tweets\n",
    "    depressive_tweets = pd.read_csv(f\"{raw_data_path}tweets/depressive_tweets_processed.csv\",\n",
    "                                   sep = '|',\n",
    "                                   header = None,\n",
    "                                   usecols = [5],\n",
    "                                   names=['tweets'])\n",
    "    # Remove missing values\n",
    "    depressive_tweets = depressive_tweets.dropna()\n",
    "    # Assign 1 to depressive tweets\n",
    "    depressive_tweets['label'] = 1\n",
    "    \n",
    "    # Concat possitive + depressive tweets\n",
    "    # Get the length of depressive tweets\n",
    "    n_depressive = len(depressive_tweets)\n",
    "    # Undersample possitive tweets\n",
    "    positive_tweets_reduced = positive_tweets.sample(n=n_depressive)\n",
    "    # Concat both datasets + shuffle their rows\n",
    "    tweets = pd.concat([positive_tweets_reduced, depressive_tweets]).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "def get_tweets_and_reddit(raw_data_path=raw_data_path):\n",
    "    \"\"\"\"Import a dataset of Tweets and Reddit Posts labeled as not depressive (0) and depressive (1)\"\"\"\n",
    "    # Import depressive Reddit posts\n",
    "    reddit = pd.read_csv(f'{raw_data_path}reddit/reddit_depression_suicidewatch.csv')\n",
    "    \n",
    "    # Remove missing values\n",
    "    reddit = reddit.dropna()\n",
    "    \n",
    "    # Filter post from subreddit depression\n",
    "    depressive_reddit = reddit[reddit['label']=='depression'].copy()\n",
    "    # Assign to depressive post the label 1\n",
    "    depressive_reddit.loc[:,'label'] = depressive_reddit['label'].map({'depression':1})\n",
    "    \n",
    "    # Import depressive tweets\n",
    "    depressive_tweets = pd.read_csv(f\"{raw_data_path}tweets/depressive_tweets_processed.csv\",\n",
    "                                   sep = '|',\n",
    "                                   header = None,\n",
    "                                   usecols = [5],\n",
    "                                   names=['text'])\n",
    "    # Remove missing values\n",
    "    depressive_tweets = depressive_tweets.dropna()\n",
    "    # Assign 1 to depressive tweets\n",
    "    depressive_tweets['label'] = 1\n",
    "    \n",
    "    # Concat depressive tweets + depressive reddit posts\n",
    "    depressive_text = pd.concat([depressive_reddit, depressive_tweets,]).reset_index(drop=True)\n",
    "    \n",
    "    # Get the length of depressive tweets\n",
    "    n_depressive_text = len(depressive_text)\n",
    "    \n",
    "    # Get possitive tweets\n",
    "    # Import data from raw_data folder\n",
    "    data = pd.read_csv(f\"{raw_data_path}tweets/training.processed.noemoticon.csv\",\n",
    "                      encoding_errors='ignore',\n",
    "                      usecols=[0,5],\n",
    "                      header=None,\n",
    "                      names=['label','text'])\n",
    "    \n",
    "    # Remove missing values\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Filter only possitive Tweets\n",
    "    positive_tweets = data[data['label']==4].drop(columns='label').reset_index(drop=True)\n",
    "    \n",
    "    # Assign 0 to not depressive tweets\n",
    "    positive_tweets['label'] = 0\n",
    "    \n",
    "    # Undersample possitive tweets to get a balanced dataset\n",
    "    positive_text_reduced = positive_tweets.sample(n=n_depressive_text)\n",
    "\n",
    "    # Concat both depressing and not_depressing text and shuffle\n",
    "    twiter_reddit = pd.concat([depressive_text, positive_text_reduced]).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return twiter_reddit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
